{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9deb67a",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4062a97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d299ce",
   "metadata": {},
   "source": [
    "# ChatGpt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b98e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "client = OpenAI() # Automatically uses the OPENAI_API_KEY from the environment variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0778a294",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "system_prompt = \"\"\"\n",
    "You are very helpful assistant that give the write the code for the user. Yours code should be very concise and clear.\n",
    "Only give the code, do not give any explanation. Write the code in Python.\n",
    "You are given a code snippet and a question about it. Your task is to provide a concise and clear answer to the question\n",
    "based on the code snippet.\n",
    "\n",
    "\"\"\"\n",
    "user_prompt = \"\"\"\n",
    "Please give me code that make gui looks like dancing leds.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e153a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "import tkinter as tk\n",
      "import random\n",
      "\n",
      "class DancingLEDs:\n",
      "    def __init__(self, root):\n",
      "        self.root = root\n",
      "        self.root.title(\"Dancing LEDs\")\n",
      "        self.canvas = tk.Canvas(root, width=400, height=200, bg='black')\n",
      "        self.canvas.pack()\n",
      "        self.leds = [self.canvas.create_oval(20 + i * 60, 80, 60 + i * 60, 120, fill='gray') for i in range(6)]\n",
      "        self.animate()\n",
      "\n",
      "    def animate(self):\n",
      "        for led in self.leds:\n",
      "            color = random.choice(['red', 'green', 'blue', 'yellow', 'magenta', 'cyan', 'white', 'gray'])\n",
      "            self.canvas.itemconfig(led, fill=color)\n",
      "        self.root.after(200, self.animate)\n",
      "\n",
      "root = tk.Tk()\n",
      "app = DancingLEDs(root)\n",
      "root.mainloop()\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = client.chat.completions.create(   # Create a chat completion\n",
    "      model =\"gpt-4o-mini\",\n",
    "      messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "      ]\n",
    ") \n",
    "print(response.choices[0].message.content)  # Print the generated code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8d38ae",
   "metadata": {},
   "source": [
    "# Ollama "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5002e689",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "24f26241",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\" \n",
    "Your are very helpful assistant that give the write the code for the user. Yours code should be very concise and clear.\n",
    "Only give the code, do not give any explanation. Write the code in Python.\n",
    "\"\"\"\n",
    "user_prompt = \"\"\"\n",
    "Please give me code that make gui looks like dancing leds.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e042b6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "\n",
    "    {\"role\":\"system\", \"content\": system_prompt},\n",
    "    {\"role\":\"user\", \"content\": user_prompt}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dac11042",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= \"qwen2.5:0.5b\"\n",
    "response = ollama.chat(model= model, messages= messages) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c746e2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "from tkinter import *\n",
      "\n",
      "root = Tk()\n",
      "\n",
      "# create the main canvas to hold the LEDs\n",
      "canvas = Canvas(root, width=500, height=200)\n",
      "canvas.pack(fill=\"both\", expand=True)\n",
      "\n",
      "# add 10 LEDs for demonstration\n",
      "for i in range(10):\n",
      "    # create a LED object and position it on the screen\n",
      "   led = Button(canvas, text=f\"LED {i+1}\")\n",
      "    led.place(x=(50 + (50 * i)), y=50)\n",
      "    \n",
      "# add some animation effects to make the LEDs dance\n",
      "root.after(100, update_leds)\n",
      "\n",
      "def update_leds():\n",
      "    for i in range(9):\n",
      "        canvas.update()\n",
      "        if canvas.winfo_ismapped():\n",
      "            x = int(canvas.winfo_x() + 50 * (i+1))\n",
      "            y = int(canvas.winfo_y() + 50)\n",
      "            \n",
      "            # toggle between red and blue\n",
      "            canvas.itemconfig(f\"LED {i+1}\", state=\"normal\")\n",
      "            \n",
      "            # add a delay to make the LEDs dance a little\n",
      "            root.after(30, update_leds)\n",
      "\n",
      "root.mainloop()\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7544be5e",
   "metadata": {},
   "source": [
    "# This project is a Personal Helping Chatbot that demonstrates how to use both OpenAI's GPT-4o-mini and Ollama's Qwen2.5:0.5b models to generate Python code based on user prompts. \n",
    "\n",
    "The notebook compares responses from both AI services when asked to create a GUI with \"dancing LEDs,\" showing how different models approach the same coding task. It serves as a practical example of integrating multiple AI APIs for code generation and comparison."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM_vsc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
