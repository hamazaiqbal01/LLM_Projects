This project converts performance-critical Python code into optimized C++ using large language models (LLMs) like GPT-4o, Claude 3.5 Sonnet, Gemini 2.0, and LLaMA. Built with Gradio, it lets users input Python code, select a model, and receive C++ output, with options to execute and compare both versions. The test task involves a random number generator and a max subarray sum algorithm. Among all models, only Claude 3.5 Sonnet generated correct C++ code on the first attempt, while GPT-4o, Gemini, and LLaMA failed to perform reliably.
